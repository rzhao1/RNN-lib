{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from swda import Transcript\n",
    "from swda import CorpusReader\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "corpus = CorpusReader('swda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(tag_list))\n",
    "    plt.xticks(tick_marks, tag_list, rotation=45)\n",
    "    plt.yticks(tick_marks, tag_list)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the tag description\n",
    "tag_detail = {}\n",
    "with open('./swda/tag_description.csv', 'r') as csv_file:\n",
    "    tag_reader = csv.reader(csv_file)\n",
    "    for row in tag_reader:\n",
    "        tag_detail[row[1]] = (row[0], row[2])\n",
    "        \n",
    "tag_map = {}\n",
    "with open('./swda/tag_mapping.csv', 'r') as csv_file:\n",
    "    tag_reader = csv.reader(csv_file)\n",
    "    for row in tag_reader:\n",
    "        tag_map[row[1]] = row[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Classificaiton Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_tokens(tokens):\n",
    "    result = []\n",
    "    for t in tokens:\n",
    "        if not ('[' in t or ']' in t or\n",
    "               '{' in t or '}' in t or \n",
    "               '+' in t or '/' in t or \n",
    "               '--' in t or \"#\" in t):\n",
    "            result.append(t)\n",
    "    return result\n",
    "    \n",
    "def should_append(utt):\n",
    "    if utt.damsl_act_tag() == '+':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def norm_label(utt):\n",
    "    label = utt.damsl_act_tag()\n",
    "    if (label.startswith(\"fo\")):\n",
    "        label = 'fo_o_fw_by_bc'\n",
    "    return tag_map[label]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_utts = []\n",
    "all_targets = []\n",
    "all_callers = []\n",
    "tag_set = set()\n",
    "cnt = 0;\n",
    "last_idx = {'A':-1, 'B':-1}\n",
    "black_list = []\n",
    "\n",
    "# create dataset\n",
    "cnt = 0\n",
    "for utt in corpus.iter_utterances(display_progress=False):\n",
    "    tokens = utt.text_words()\n",
    "    caller = utt.caller\n",
    "    label = norm_label(utt)\n",
    "    b_should_append = should_append(utt)\n",
    "    \n",
    "    # check for merging\n",
    "    if b_should_append:\n",
    "        idx = last_idx.get(caller)\n",
    "        if idx >= 0:\n",
    "            all_utts[idx] = all_utts[idx] + ' ' + ' '.join(norm_tokens(tokens))\n",
    "            continue\n",
    "        else:\n",
    "            print \"ERROR\"\n",
    "            break\n",
    "    \n",
    "    # check if empty\n",
    "    norm_text = ' '.join(norm_tokens(tokens))\n",
    "    if not norm_text:\n",
    "        if label == 'x' and utt.text:\n",
    "            norm_text = utt.text\n",
    "        else:       \n",
    "            continue\n",
    "        \n",
    "    # update previous speaker utt\n",
    "    last_idx[caller] = cnt\n",
    "    \n",
    "    # save\n",
    "    all_utts.append(norm_text)\n",
    "    all_targets.append(label)\n",
    "    all_callers.append(caller)\n",
    "    tag_set.add(label)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196258 train\n",
      "7387 test\n"
     ]
    }
   ],
   "source": [
    "train_size = 196258\n",
    "test_size = len(all_utts) - train_size\n",
    "\n",
    "train_utts = all_utts[0:train_size]\n",
    "test_utts = all_utts[train_size:train_size+test_size]\n",
    "\n",
    "y_train = np.zeros(train_size)\n",
    "y_test = np.zeros(test_size)\n",
    "tag_list = list(tag_set)\n",
    "\n",
    "tag_names = [x[0] for x in tag_detail.values()]\n",
    "\n",
    "print str(len(y_train)) + \" train\"\n",
    "print str(len(y_test)) + \" test\"\n",
    "\n",
    "for idx, target in enumerate(all_targets):\n",
    "    if idx >= train_size + test_size:\n",
    "        break\n",
    "    if idx < train_size:\n",
    "        y_train[idx] = tag_list.index(target)\n",
    "    else:\n",
    "        y_test[idx-train_size] = tag_list.index(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "representation = CountVectorizer(min_df=1, ngram_range=(1,3), lowercase=False)\n",
    "representation.fit(train_utts)\n",
    "X_train = representation.transform(train_utts)\n",
    "X_test = representation.transform(test_utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=22).fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.mean(predicted == y_test)\n",
    "print metrics.classification_report(y_test, predicted, target_names=tag_list)\n",
    "plot_confusion_matrix(metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
